{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refs: \\\n",
    "https://pytorch.org/docs/stable/tensors.html \\\n",
    "https://jovian.ai/aakashns/01-pytorch-basics \\\n",
    "https://www.youtube.com/watch?v=GIsg-ZUy0MY \\\n",
    "https://www.youtube.com/watch?v=exaWOE8jvy8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a tensor\n",
    "A tensor is a number, vector, matrix or any n-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number\n",
    "t1 = torch.tensor(2.)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 5., 8.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "t2 = torch.tensor([1., 2, 5, 8.])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13],\n",
       "        [21, 22, 23]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix\n",
    "t3 = torch.tensor([[11,12, 13], [21, 22, 23]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000e+00, -2.5244e-29,  1.4329e+10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2111, 0.2224],\n",
       "        [0.4734, 0.0069],\n",
       "        [0.6136, 0.6834]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a one-dimensional tensor of size 3:\n",
    "x = torch.ones(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3,2, dtype=torch.int32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12],\n",
       "        [21, 22],\n",
       "        [31, 32]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[11, 12], [21, 22], [31, 32]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12],\n",
       "        [21, 22]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 22, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(102.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.)\n",
    "print(x)\n",
    "\n",
    "y = x + 100\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3)\n",
    "print(x)\n",
    "\n",
    "x[2] = 3.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12],\n",
      "        [21, 22]])\n",
      "tensor([[111, 112],\n",
      "        [121, 122]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[11, 12], [21, 22]])\n",
    "print(x)\n",
    "\n",
    "y = x + 100\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12],\n",
      "        [21, 22]])\n",
      "tensor([[1000, 2000],\n",
      "        [3000, 4000]])\n",
      "tensor([[1011, 2012],\n",
      "        [3021, 4022]])\n"
     ]
    }
   ],
   "source": [
    "## addition\n",
    "x = torch.tensor([[11, 12], [21, 22]])\n",
    "print(x)\n",
    "\n",
    "y = torch.tensor([[1000, 2000], [3000, 4000]])\n",
    "print(y)\n",
    "\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12],\n",
      "        [21, 22]])\n",
      "tensor([[1000, 2000],\n",
      "        [3000, 4000]])\n",
      "tensor([[11000, 24000],\n",
      "        [63000, 88000]])\n"
     ]
    }
   ],
   "source": [
    "## element multiplication\n",
    "x = torch.tensor([[11, 12], [21, 22]])\n",
    "print(x)\n",
    "\n",
    "y = torch.tensor([[1000, 2000], [3000, 4000]])\n",
    "print(y)\n",
    "\n",
    "z = x * y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10, 100],\n",
      "        [ 20, 200]])\n",
      "tensor([[1000, 2000],\n",
      "        [3000, 4000]])\n",
      "tensor([[100.,  20.],\n",
      "        [150.,  20.]])\n"
     ]
    }
   ],
   "source": [
    "## element division\n",
    "x = torch.tensor([[10, 100], [20, 200]])\n",
    "print(x)\n",
    "\n",
    "y = torch.tensor([[1000, 2000], [3000, 4000]])\n",
    "print(y)\n",
    "\n",
    "z = y / x\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12],\n",
      "        [21, 22],\n",
      "        [31, 32]])\n",
      "tensor([[11, 12, 21],\n",
      "        [22, 31, 32]])\n",
      "tensor([11, 12, 21, 22, 31, 32])\n"
     ]
    }
   ],
   "source": [
    "## reshape\n",
    "x = torch.tensor([[11, 12], [21, 22], [31, 32]])\n",
    "print(x)\n",
    "\n",
    "x1 = x.reshape(2,3)\n",
    "print(x1)\n",
    "\n",
    "x2 = x.reshape(-1,)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12],\n",
      "        [21, 22],\n",
      "        [31, 32]]) torch.Size([3, 2])\n",
      "tensor([[11, 21, 31],\n",
      "        [12, 22, 32]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "## 2D transpose\n",
    "x = torch.tensor([[11, 12], [21, 22], [31, 32]])\n",
    "print(x, x.shape)\n",
    "\n",
    "y = x.t() \n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 11,  12,  13,  14],\n",
      "         [ 21,  22,  23,  24],\n",
      "         [ 31,  32,  33,  34]],\n",
      "\n",
      "        [[101, 102, 103, 104],\n",
      "         [201, 202, 203, 204],\n",
      "         [301, 302, 303, 304]]]) torch.Size([2, 3, 4])\n",
      "tensor([[[ 11, 101],\n",
      "         [ 21, 201],\n",
      "         [ 31, 301]],\n",
      "\n",
      "        [[ 12, 102],\n",
      "         [ 22, 202],\n",
      "         [ 32, 302]],\n",
      "\n",
      "        [[ 13, 103],\n",
      "         [ 23, 203],\n",
      "         [ 33, 303]],\n",
      "\n",
      "        [[ 14, 104],\n",
      "         [ 24, 204],\n",
      "         [ 34, 304]]]) torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "## for higher transpose, need to specify the two dimensions\n",
    "x = torch.tensor([[[11,12,13, 14], [21,22,23,24], [31,32,33,34]],\n",
    "                  [[101,102,103, 104], [201,202,203,204], [301,302,303,304]]])\n",
    "print(x, x.shape)\n",
    "\n",
    "y = x.transpose(0,2) \n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13, 16])\n",
      "tensor(12)\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "## covert tensor to plain Python\n",
    "x = torch.tensor([11,12,13,16])\n",
    "print(x)\n",
    "\n",
    "print(x[1])\n",
    "\n",
    "print(float(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12],\n",
      "        [21, 22],\n",
      "        [31, 32]])\n",
      "[[11 12]\n",
      " [21 22]\n",
      " [31 32]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[11 12]\n",
      " [21 22]\n",
      " [31 32]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "## convert torch to numpy\n",
    "x = torch.tensor([[11, 12], [21, 22], [31, 32]])\n",
    "print(x)\n",
    "\n",
    "y = x.numpy()\n",
    "print(y)\n",
    "print(type(y))\n",
    "\n",
    "z = np.array(x)\n",
    "print(z)\n",
    "print(type(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 12]\n",
      " [21 22]\n",
      " [31 32]]\n",
      "tensor([[11, 12],\n",
      "        [21, 22],\n",
      "        [31, 32]])\n",
      "  \n",
      "[[111 112]\n",
      " [121 122]\n",
      " [131 132]]\n",
      "tensor([[111, 112],\n",
      "        [121, 122],\n",
      "        [131, 132]])\n"
     ]
    }
   ],
   "source": [
    "## convert numpy to torch\n",
    "x = np.array([[11, 12], [21, 22], [31, 32]])\n",
    "print(x)\n",
    "\n",
    "y = torch.from_numpy(x)\n",
    "print(y)\n",
    "\n",
    "print('  ')\n",
    "x += 100\n",
    "print(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of image tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D tensor for image: [channels, rows, columns]\n",
    "img_t = torch.randn(3,5,5)  # shape [channels, rows, columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with bathch_t: batch_t = 2 for instance\n",
    "batch_t = torch.randn(2,3,5,5)  # shape [batch, channels, rows, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-3.2108e-01,  1.3435e-01, -5.1875e-01, -8.2088e-01, -1.5634e+00],\n",
       "          [-1.7870e-01, -3.3559e-01,  1.2007e-01, -1.3797e+00, -1.1352e+00],\n",
       "          [ 4.4099e-01,  1.5231e+00, -1.2819e-01,  1.8978e-01, -1.0727e+00],\n",
       "          [-3.1410e-01, -1.5475e+00,  1.1043e+00, -4.8423e-01,  2.8692e-01],\n",
       "          [-1.1729e+00, -2.2115e+00, -4.4963e-01, -2.2801e+00,  1.8238e-01]],\n",
       "\n",
       "         [[-9.9248e-01, -6.9789e-02, -5.5713e-01, -1.3315e-03, -3.8328e-01],\n",
       "          [-1.8814e-01, -1.8258e+00, -2.7561e-01, -4.4539e-01, -1.1003e+00],\n",
       "          [ 3.1505e-01, -2.6726e-01,  2.3241e-01, -3.8361e-01, -1.4943e+00],\n",
       "          [-8.2953e-01,  9.1905e-02,  1.0462e+00, -1.1005e+00, -7.6292e-01],\n",
       "          [-1.2825e-01,  4.4365e-01,  1.3688e+00,  5.6648e-01, -1.1249e+00]],\n",
       "\n",
       "         [[-1.0681e+00, -1.7074e+00, -3.2214e-01, -1.3174e-01, -2.3485e-01],\n",
       "          [ 7.6626e-01,  1.4221e+00, -1.2236e+00, -8.1489e-01, -3.6494e-01],\n",
       "          [ 5.7969e-01,  5.8682e-01, -1.5262e+00,  1.3709e+00,  4.4790e-01],\n",
       "          [-3.0655e+00, -2.1373e-01,  1.7013e-02,  5.8917e-01, -6.0307e-01],\n",
       "          [-5.3190e-01, -1.0890e-01,  1.2953e+00,  8.5717e-01, -2.9692e-01]]],\n",
       "\n",
       "\n",
       "        [[[-5.0993e-02, -3.3000e+00, -8.1269e-01, -4.1171e-02,  3.4091e-01],\n",
       "          [ 2.0491e+00, -9.0043e-01, -1.9439e+00,  1.8772e+00,  1.5043e+00],\n",
       "          [ 1.1632e+00,  7.2369e-01, -1.2514e-01,  4.0875e-01,  3.1176e-01],\n",
       "          [ 3.0690e-01, -5.4423e-01, -1.1637e+00,  6.1999e-01,  3.4591e-01],\n",
       "          [-1.5363e-01,  9.1119e-01, -3.1450e-02,  1.2570e+00, -1.2617e+00]],\n",
       "\n",
       "         [[-5.3828e-01,  1.3014e-01, -1.5323e+00,  3.3298e-01,  1.2124e+00],\n",
       "          [-8.5530e-01, -2.4175e+00,  1.5884e+00, -1.4961e-03, -8.3107e-02],\n",
       "          [-2.9293e-01,  1.3709e+00, -1.1492e+00,  3.0010e-01,  9.3965e-01],\n",
       "          [ 1.3066e+00, -4.6471e-01, -4.3341e-01,  4.3202e-02,  7.5247e-01],\n",
       "          [-6.9464e-01, -1.2722e+00,  1.1749e+00, -7.6864e-01, -1.4867e-02]],\n",
       "\n",
       "         [[ 4.4208e-01, -1.8929e-01,  2.9183e-01,  8.0475e-01,  9.9661e-02],\n",
       "          [-9.6512e-01,  6.9495e-01,  1.2999e+00,  1.6865e-01, -8.5992e-01],\n",
       "          [ 4.6492e-01, -2.0255e-02,  9.9314e-01, -5.8952e-01,  2.1858e-01],\n",
       "          [-3.3799e-02, -4.5794e-01,  9.1771e-01,  2.0378e-01,  1.8343e+00],\n",
       "          [ 3.6656e-01, -2.5556e+00,  1.1042e+00,  3.9152e-01, -5.2001e-01]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## So sometimes the RBG channels are in dimension 0, and sometimes they are in dimension 1. \n",
    "## But they are always the 3rd from the end -- dimension -3. So the unweighted mean can be calculated:\n",
    "\n",
    "img_gray_native = img_t.mean(-3)\n",
    "\n",
    "batch_gray_native = batch_t.mean(-3)\n",
    "\n",
    "img_gray_native.shape, batch_gray_native.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "## With weights, PyTorch allows to multiply tensors of the same shape, as well as shapes where \n",
    "## one operand is of size 1 in a given dimension: (2,3,5,5) x (3,1,1) --> (2,3,5,5)\n",
    "\n",
    "print(weights.shape)\n",
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "print(unsqueezed_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 5])\n",
      "torch.Size([3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(img_t.shape)\n",
    "\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "\n",
    "print(img_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5, 5])\n",
      "torch.Size([2, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(batch_t.shape)\n",
    "\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "\n",
    "print(batch_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "img_gray_weighted = img_weights.sum(-3)\n",
    "print(img_gray_weighted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "print(batch_gray_weighted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "\n",
    "print(batch_gray_weighted_fancy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/u1094325/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:848.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 5])\n",
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "## Use `refine_names` to add names to a tensor (but not change existing ones):\n",
    "print(img_t.shape)\n",
    "\n",
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns') \n",
    "print(\"img named:\", img_named.shape, img_named.names)\n",
    "print(\"batch named:\", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "torch.Size([3]) ('channels',)\n",
      "torch.Size([3, 1, 1]) ('channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "## align_as: aligns dimensions, returns a tensor with missing dimensions added:\n",
    "print(img_named.shape, img_named.names)\n",
    "print(weights_named.shape, weights_named.names)\n",
    "\n",
    "weights_aligned = weights_named.align_as(img_named) \n",
    "\n",
    "print(weights_aligned.shape, weights_aligned.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5]) ('rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "\n",
    "print(gray_named.shape, gray_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5]) ('rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum(axis=0)\n",
    "\n",
    "print(gray_named.shape, gray_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5]) (None, None)\n"
     ]
    }
   ],
   "source": [
    "## drop names\n",
    "gray_plain = gray_named.rename(None)\n",
    "\n",
    "print(gray_plain.shape, gray_plain.names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
